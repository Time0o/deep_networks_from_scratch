\documentclass{article}

\usepackage{float}
\usepackage{svg}

\begin{document}

\title{DD2424 - Assignment 3 Bonus}
\author{Timo Nicolai}

\maketitle

\noindent
I attempted to incorporate the following four techniques: increasing the depth
of the network, increasing the size of its hidden layers, applying dropout
and augmenting the dataset by mirroring all training images. I will describe
each of these in a separate section below.

\section{Increasing Depth}

As a simple sanity check I tried appending a single additional hidden layer to
the best three layer network found in the non-bonus part of this assignment.
Figure~\ref{fig:depth} shows the resulting validation set accuracies achieved
by varying the size of this addtional hidden layer (hyperparameters are as
before with the same $\lambda$ found via grid search and batch normalization
enabled, I trained for two cycles in each case).

\begin{figure}[H]
  \centering
    \footnotesize
    \begin{tabular}{|c|c|}
    \hline
    Hidden Node in 3rd Hidden Layer & Accuracy \\
    \hline
    30                              & 0.5498   \\
    \hline
    40                              & 0.5504   \\
    \hline
    50                              & 0.5528   \\
    \hline
    60                              & 0.5446   \\
    \hline
    70                              & 0.5464   \\
    \hline
    \end{tabular}
  \caption{Validation set accuracy achieved by appending a third hidden layer
           of varying size.}
  \label{fig:depth}
\end{figure}

\noindent
Unfortunately, adding another hidden layer does not seem to improve validation
set accuracy, it is possible that training a deeper network with good
performance would require larger hidden layers in combination with more
elaborate regularization.  I did however not have the hardware resources to
perform more exhaustive tests here so I decided to stick with a three layer
network.

\section{Larger Hidden Layers}

Figure~\ref{fig:width} shows the accuracies achieved by training a three layer
network with larger hidden layers. Increasing the size of the hidden layers
seems to significantly improve validation set accuracy, but this effect
strongly diminishes after around $300$ nodes in each hidden layer. To retain
a reasonable training time I therefore decided to use $300$ node in both hidden
layers from here on.

\begin{figure}[H]
  \centering
    \footnotesize
    \begin{tabular}{|c|c|}
    \hline
    Hidden Layer Nodes & Accuracy \\
    \hline
    100, 100           & 0.5614   \\
    \hline
    200, 200           & 0.5846   \\
    \hline
    300, 300           & 0.604    \\
    \hline
    400, 400           & 0.6016   \\
    \hline
    500, 500           & 0.6048   \\
    \hline
    \end{tabular}
  \caption{Validation set accuracies achieved by increasing the size of the
           hidden layers.}
  \label{fig:width}
\end{figure}

\section{Dropout}

Applying inverted dropout with a dropout probability of $50\%$ during training
dropped validation set accuracy down to less than $0.5$, so I did not use
it when training the final network.

\section{Data Augmentation}

As a data augmentation measure I doubled the size of the training set by
mirroring each image horizontally. To actually make use of the enlarged dataset
I also trained for more cycles (six to be exact).
Figure~\ref{fig:final_curves} shows the training curves from this final
training run and Figure~\ref{fig:final_performance} shows the test set
confusion matrix for the trained network.

Unfortunately it seems like neither training set augmentation nor longer
training time significantly improve the networks performance. The final network
does however perform slightly better than the baseline network before
attempting any optimizations. The only real improvement was due to the increase
in hidden layer sizes.

\begin{figure}[H]
  \centering
    \includesvg[width=0.65\textwidth]{../figures/learning_curves_augment.svg}
  \caption{Training curves for the final network trained on augmented data.}
  \label{fig:final_curves}
\end{figure}

\begin{figure}[H]
  \centering
    \includesvg[width=0.65\textwidth]{../figures/performance_augment.svg}
  \caption{Test set confusion matrix for the final network trained on augmented
           data.}
  \label{fig:final_performance}
\end{figure}

\end{document}
