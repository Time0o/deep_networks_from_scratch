{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.append('../lib')\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data import Cifar\n",
    "from history import TrainHistory\n",
    "from search import SearchParam, SearchResultSeries, search\n",
    "from two_layer_fully_connected import TwoLayerFullyConnected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "PICKLE_DIR = '../pickle'\n",
    "FIGURE_DIR = '../figures'\n",
    "\n",
    "HIDDEN_NODES = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Cifar(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = dataset.train_val_test_split(\n",
    "    n_val=5000, normalize='zscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default network constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = SearchResultSeries.load(\n",
    "    PICKLE_DIR, postfix='fine')\n",
    "\n",
    "default_network = partial(\n",
    "    TwoLayerFullyConnected,\n",
    "    input_size=data_train.input_size,\n",
    "    hidden_nodes=HIDDEN_NODES,\n",
    "    num_classes=data_train.num_classes,\n",
    "    alpha=search_results.optimum()['alpha'],\n",
    "    random_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reference network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = default_network()\n",
    "\n",
    "history = network.train_cyclic(data_train,\n",
    "                               data_val,\n",
    "                               eta_ss=(2 * data_train.n // 100),\n",
    "                               n_cycles=3,\n",
    "                               verbose=True)\n",
    "\n",
    "history.save(PICKLE_DIR, postfix='reference_three_cycles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = TrainHistory.load(PICKLE_DIR, postfix='reference_three_cycles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.visualize()\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'curves_reference_three_cycles.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.final_network.visualize_performance(data_val)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'performance_reference_three_cycles.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = [50, 100, 200, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hn in hidden_nodes:\n",
    "    network = TwoLayerFullyConnected(\n",
    "        input_size=data_train.input_size,\n",
    "        hidden_nodes=hn,\n",
    "        num_classes=data_train.num_classes,\n",
    "        alpha=search_results.optimum()['alpha'],\n",
    "        random_seed=0)\n",
    "\n",
    "    history = network.train_cyclic(\n",
    "        data_train,\n",
    "        data_val,\n",
    "        eta_ss=(2 * data_train.n // 100),\n",
    "        n_cycles=3,\n",
    "        verbose=True)\n",
    "    \n",
    "    postfix = 'two_layers_{}_nodes'.format(h)\n",
    "    history.save(PICKLE_DIR, postfix=postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax_train, ax_val) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for hn in hidden_nodes:\n",
    "    postfix = 'two_layers_{}_nodes'.format(hn)\n",
    "    history = TrainHistory.load(PICKLE_DIR, postfix=postfix)\n",
    "    \n",
    "    ax_train.plot(history.domain,\n",
    "                  history.train_accuracy,\n",
    "                  label=\"{} Hidden Nodes\".format(hn))\n",
    "\n",
    "    ax_val.plot(history.domain,\n",
    "                history.val_accuracy,\n",
    "                label=\"{} Hidden Nodes\".format(hn))\n",
    "    \n",
    "ax_train.set_title(\"Training Set\")\n",
    "ax_val.set_title(\"Validation Set\")\n",
    "\n",
    "for ax in ax_train, ax_val:\n",
    "    ax.set_xlabel(\"Update Step\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    \n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'more_hidden_nodes.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = TrainHistory.load(PICKLE_DIR, postfix='two_layers_400_nodes')\n",
    "\n",
    "history.final_network.visualize_performance(data_val)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'performance_two_layers_400_nodes.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = SearchResultSeries.load(\n",
    "    PICKLE_DIR, postfix='fine')\n",
    "\n",
    "default_network = partial(\n",
    "    TwoLayerFullyConnected,\n",
    "    input_size=data_train.input_size,\n",
    "    hidden_nodes=400,\n",
    "    num_classes=data_train.num_classes,\n",
    "    alpha=search_results.optimum()['alpha'],\n",
    "    random_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform more exhaustive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "alpha = SearchParam('alpha', -5, -2, n_samples, scale='log')\n",
    "eta_ss = SearchParam('eta_ss', 200, 2000, n_samples, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(param_args):\n",
    "    network = default_network(alpha=param_args['alpha'])\n",
    "    \n",
    "    return network.train_cyclic(\n",
    "        data_train,\n",
    "        data_val,\n",
    "        eta_ss=param_args['eta_ss'],\n",
    "        n_cycles=int(round(2000 / param_args['eta_ss'])),\n",
    "        verbose=True)\n",
    "\n",
    "for random_seed in range(3):\n",
    "    search_results = search(data_train,\n",
    "                            data_val,\n",
    "                            params=[alpha, eta_ss],\n",
    "                            train_function=train_function,\n",
    "                            random_seed=random_seed)\n",
    "\n",
    "    search_results.save(\n",
    "        PICKLE_DIR, postfix='exhaustive_seed{}'.format(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = None\n",
    "\n",
    "for random_seed in range(3):\n",
    "    _search_results = SearchResultSeries.load(\n",
    "        PICKLE_DIR, postfix='exhaustive_seed{}'.format(random_seed))\n",
    "    \n",
    "    if search_results is None:\n",
    "        search_results = _search_results\n",
    "    else:\n",
    "        search_results = search_results.join(_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.visualize(alpha, eta_ss)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'exhaustive_coarse.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "alpha = SearchParam('alpha', np.log10(5e-4), np.log10(2e-3), n_samples, scale='log')\n",
    "eta_ss = SearchParam('eta_ss', 1000, 1250, n_samples, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(param_args):\n",
    "    network = default_network(alpha=param_args['alpha'])\n",
    "\n",
    "    return network.train_cyclic(\n",
    "        data_train,\n",
    "        data_val,\n",
    "        eta_ss=param_args['eta_ss'],\n",
    "        n_cycles=int(round(2000 / param_args['eta_ss'])),\n",
    "        verbose=True)\n",
    "\n",
    "for random_seed in range(3):\n",
    "    search_results = search(data_train,\n",
    "                            data_val,\n",
    "                            params=[alpha, eta_ss],\n",
    "                            train_function=train_function,\n",
    "                            random_seed=random_seed)\n",
    "\n",
    "    search_results.save(\n",
    "        PICKLE_DIR, postfix='exhaustive_fine_seed{}'.format(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = None\n",
    "\n",
    "for random_seed in range(3):\n",
    "    _search_results = SearchResultSeries.load(\n",
    "        PICKLE_DIR, postfix='exhaustive_fine_seed{}'.format(random_seed))\n",
    "\n",
    "    if search_results is None:\n",
    "        search_results = _search_results\n",
    "    else:\n",
    "        search_results = search_results.join(_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.visualize(alpha, eta_ss)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'exhaustive_fine.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0, 0.5, 0.6]:\n",
    "    network = default_network(dropout=p)\n",
    "\n",
    "    history = network.train_cyclic(\n",
    "        data_train,\n",
    "        data_val,\n",
    "        eta_ss=(2 * data_train.n // 100),\n",
    "        n_cycles=3,\n",
    "        verbose=True)\n",
    "\n",
    "    postfix = 'two_layers_dropout{}'.format(\n",
    "        str(p).replace('.', '_'))\n",
    "\n",
    "    history.save(PICKLE_DIR, postfix=postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0, 0.4, 0.5, 0.6]:\n",
    "    postfix = 'two_layers_dropout{}'.format(\n",
    "        str(p).replace('.', '_'))\n",
    "\n",
    "    history = TrainHistory.load(PICKLE_DIR, postfix=postfix)\n",
    "    \n",
    "    print(history.final_network.accuracy(data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = dataset.train_val_test_split(\n",
    "    n_val=1000, normalize='zscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = default_network()\n",
    "\n",
    "history = network.train_cyclic(\n",
    "    data_train,\n",
    "    data_val,\n",
    "    eta_ss=(2 * data_train.n // 100),\n",
    "    n_cycles=10,\n",
    "    create_ensemble=True,\n",
    "    verbose=True)\n",
    "\n",
    "history.save(PICKLE_DIR, postfix='minimum_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = TrainHistory.load(PICKLE_DIR, postfix='minimum_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.visualize()\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'curves_minimum_ensemble.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.final_network.visualize_performance(data_test)\n",
    "\n",
    "plt.savefig(os.path.join(FIGURE_DIR, 'performance_minimum_ensemble.svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
